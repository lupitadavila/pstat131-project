circuit.aov1 <- aov(time~type,data=circuit)
summary(circuit.aov1,split=list(type=list(1,2)))
### which type would you select to minimize the response time?
# Ans: Type 1 or Type 3.
### Analyize residuals
# normality
resid <- circuit.aov$resid
qqnorm(resid)
qqline(resid)
shapiro.test(resid)
# Check outlier
rstand <- resid/sqrt(17.1)
plot(rstand, ylab="Standard Residuals", main="Plot of Standard Residuals")
# Check constant variance
fit <- circuit.aov$fitted
plot(fit, resid, xlab="Predicted Values", ylab="Residuals", main="Plot of Residuals \n Versus Predicted Values")
### Problem 3.24 ####
### Lupita Davila ###
### input data
type <- rep(1:4, each=5)
type <- as.factor(type)
time <- c(19, 20, 19, 30, 8, 80, 61, 73, 56, 80, 47, 26, 25, 35, 50, 95, 46, 83, 78, 97)
(circuit <- data.frame(type, time))
### test the hypothesis that the three types have the same response time, alpha=0.01
circuit.aov <- aov(time ~ type, data=circuit)
summary(circuit.aov)
anova(circuit.aov) # p-value < 0.05, significant
### use Tukey's test to compare pairs of treatment means
TukeyHSD(circuit.aov, conf.level=0.99)
# Scheffe's Method for comparing all contrasts
MSE <- 17.1
c1 <- c(1,-1,0)
c2 <- c(1,0,-1)
c3 <- c(0,1,-1)
ybar <- c(mean(time[1:5]),mean(time[6:10]),mean(time[11:15]))
c(sum(c1*ybar)-sqrt(2*qf(0.95,2,13)*MSE*sum(c1^2)/5),sum(c1*ybar)+sqrt(2*qf(0.95,2,13)*MSE*sum(c1^2)/5))
c(sum(c2*ybar)-sqrt(2*qf(0.95,2,13)*MSE*sum(c2^2)/5),sum(c2*ybar)+sqrt(2*qf(0.95,2,13)*MSE*sum(c2^2)/5))
c(sum(c3*ybar)-sqrt(2*qf(0.95,2,13)*MSE*sum(c3^2)/5),sum(c3*ybar)+sqrt(2*qf(0.95,2,13)*MSE*sum(c3^2)/5))
### use the graphical procedure to compare the treatment means
MSE <- 17.1 # get from ANOVA table
tbase <- seq(-10,10,length=200)
t <- dt(tbase,df=12)
tscale <- t*sqrt(MSE/15)
plot(tbase+mean(time),tscale,type="l",xaxt='n',xlab='',yaxt='n',ylab='')
axis(side=1,at=mean(time[1:5]))
axis(side=1,at=mean(time[6:10]))
axis(side=1,at=mean(time[11:15])) # consistent with Tukey's procedure
plot(type, time, xlab="Type", ylab="Time")
### construct orthogonal constrasts, to test the suspecion that response time of type 2 is different from the other two
(con.m <- matrix(c(1,0,-1,1,-2,1),nrow=3))
contrasts(circuit$type) <- con.m
circuit.aov1 <- aov(time~type,data=circuit)
summary(circuit.aov1,split=list(type=list(1,2)))
### which type would you select to minimize the response time?
# Ans: Type 1 or Type 3.
### Analyize residuals
# normality
resid <- circuit.aov$resid
qqnorm(resid)
qqline(resid)
shapiro.test(resid)
# Check outlier
rstand <- resid/sqrt(17.1)
plot(rstand, ylab="Standard Residuals", main="Plot of Standard Residuals")
# Check constant variance
fit <- circuit.aov$fitted
plot(fit, resid, xlab="Predicted Values", ylab="Residuals", main="Plot of Residuals \n Versus Predicted Values")
q()
dat <- read.table("http://astrostatistics.psu.edu/su09/lecturenotes/sat.dat")
data <- read.table("http://astrostatistics.psu.edu/su09/lecturenotes/sat.dat")
dim(data) # The above image, for example, is made of 3000 dots,
# arranged in a rectangle that is 75 dots wide and 40 dots high
# Each dot, by the way, is called a pixel
# (a short form for "picture element").
# Assign names of clums
# The camera reports the red-ness, green-ness and blue-ness of each pixel
names(data) <- c("red","green","blue")
attach(data)
# Next make a vector of colors, one color for each point.
mycol <- rgb(red,green,blue,max=255)
# The function rgb makes colors by combining red, green and blue values.
# The max specification means 255 is to be considered the highest value for
# each color.
# Next we need to specify the size of the image.
# It is 75 pixels in width and 40 pixels in height.
rows <- 1:75
columns <- 1:40
# So the 3000 points are actually arranged as a 40 by 75 matrix.
# (The height, 40, is the number of rows.)
z <- matrix(1:3000,nrow=75)
# Now we are ready to make the image.
image(rows,columns,z,col=mycol)
# If you do not like to see the axes and labels,
# then you may remove them using
image(rows,columns,z,col=mycol,bty="n",yaxt="n",
xaxt="n",xlab="",ylab="")
############################
# Based on the 3000 points the statistical brain of the satellite has to decide
# that is seeing two land masses peeping out from a vast blue ocean.
# And one important tool to achieve this is called clustering.
# But before we go into it let us make a 3D scatterplot out of the 3 variables.
library(scatterplot3d)
install.packages("scatterplot3d")
library(scatterplot3d)
# Warning! It won't work unless
# scatterplot3d is installed.
# I mention this to explain how
# you may do it if you can download
# this (pretty large) package.
# Also, this package is readily available for
# only Windows. To use it in Linux, you have
# to download the source code and compile!
# But we shall see a work around for this soon.
# Then you can use:
scatterplot3d(red,green,blue,color=mycol)
# One problem with scatterplot3d is that there is no simple way to
# specify the viewing angle. This is rectified in the small script scat3d.r,
# which you can download. Now use
source("http://astrostatistics.psu.edu/su09/lecturenotes/scat3d.r")
scat3d(red,green,blue,col=mycol)
# You can also turn the plot around specifying the
# angles theta and phi as follows
scat3d(red,green,blue,col=mycol,theta = 60, phi=0)
###########################################################################3
#                         K means Implementation
###########################################################################3
# Apply the command
cl <- kmeans(dat,2)
cl <- kmeans(data,2)
# and see what kmeans has returned.
names(cl)
cl$clus
# Each pixel is put into one of two clusters (called 1 and 2),
# and cl$clus tells us the cluster of each pixel.
# The centers of the two clusters are given by
cl$center
# Now we shall make an image of the clustering result.
# We are going to have an image consisting of only two colors,
# one for each cluster. It is natural to choose the center as the
#representative color for a cluster.
c2 <- rgb(cl$cen[,1],cl$cen[,2],cl$cen[,3],max=255)
c2
# Next we have to wrap the long vector cl$clus in to a 75 by 40 matrix
# in order to make the image.
image(rows,columns, matrix(cl$clus,75,40),col=c2)
# Do you think that the ocean is well-separated from the land?
# What about adding some more details? For this we shall increase k to 3, say.
cl <- kmeans(dat,3)
c3 <- rgb(cl$cen[,1],cl$cen[,2],cl$cen[,3],max=255)
cl <- kmeans(data,3)
c3 <- rgb(cl$cen[,1],cl$cen[,2],cl$cen[,3],max=255)
image(rows,columns, matrix(cl$clus,75,40),col=c3)
# As you increase the number of clusters more and more details are added to the image. Notice that in our example the details get added to the land masses instead of the ocean which is just a flat
# uninteresting sheet of water.
# As you increase the number of clusters more and more details are added to the image. Notice that in our example the details get added to the land masses instead of the ocean which is just a flat
# uninteresting sheet of water.
elder <-c(19,30,20,19,29,25,21,24,50)
young <-c(25,21,17,15,14,14,22,17)
mean(elder)
var(elder)
mean(young)
var(young)
t.test(elder,young)
t.test(elder)
t.test(elder, young, alternative= "two.sided", paired= FALSE)
t.test(elder, young, alternative= "two.sided", paired= FALSE, var.equal=TRUE)
elder <-c(19,30,20,19,29,25,21,24)
young <-c(25,21,17,15,14,14,22,17)
t.test(elder, young, alternative= "two.sided", paired= FALSE, var.equal=TRUE)
t.test(calle, hollister, alternative= "two.sided", paired= FALSE, var.equal=TRUE)
calle <-c(15.78,17.73,10.61,15.79,
14.22,13.82,13.45,12.86,
10.82,12.85)
hollister<-c(15.19,18.22,15.38,15.96,
21.92,12.87, 12.47,13.96,
13.79,13.74,18.4,18.57,
17.79,10.83)
t.test(calle, hollister, alternative= "two.sided", paired= FALSE, var.equal=TRUE)
var(calle)
var(hollister)
t.test(calle, hollister, alternative= "two.sided", paired= FALSE)
hist(calle)
hist(hollister)
hist(calle)
t.test(elder, young, alternative= "two.sided", paired= FALSE, var.equal=FALSE)
t.test(calle, hollister, alternative= "two.sided", paired= FALSE, var.equal=FALSE)
plot(cos, -pi,  3*pi)
plot(cos, -pi,  3*pi)
factorial(x)
plot(factorial(x), 2, 100)
equation <- factorial(x)
x <- 2:100
plot(factorial(x))
plot(factorial(x), 2, 100)
plot(factorial(x)/x)
plot(0.0938, 1)
View(x)
plot(factorial(x)/(x^x),1:99)
plot(factorial(x)/(x^x))
plot(factorial(x)/(x^x))
y <- 1:99
plot(factorial(x)/(x^x), y)
plot(y,factorial(x)/(x^x))
plot(y,factorial(x)/(x^x))
plot(factorial(x)/(x^x))
plot(factorial(x)/(x^x), main = "probability of obtaining one point from each cluster in a sample of size K")
plot(factorial(x)/(x^x), main = "probability of obtaining one point from each cluster")
plot(factorial(x)/(x^x), main = "P(obtaining one point from each cluster)")
plot(factorial(x)/(x^x), main = "Prob(obtaining one point from each cluster)")
plot(factorial(x)/(x^x), main = "Probability Plot")
k <- 2000
k <- 2000
factorial(k)/(k^k)
k <- 10
factorial(k)/(k^k)
k <- 100
factorial(k)/(k^k)
k <- 1000
factorial(k)/(k^k)
k <- 10
factorial(k)/(k^k)
k <- 100
factorial(k)/(k^k)
k <- 1000
factorial(k)/(k^k)
k <- 10
factorial(2k)/(2k^2k)
factorial(2*k)/(2*k^2*k)
factorial(2*k)/(2*k^(2*k))
k <- 20
factorial(k)/(k^(k))
k <- 20
factorial(k)/(k^k)
k <- 20
factorial(k)/(k^k)
(1 − (1/K))^2K
(1−(1/k))^2k
(1−(1/k))^(2*k)
k <- 10
(1−(1/k))^(2*k)
.1215*2
k <- 10
(1−(1/k))^(2*k)
(1−(1/k))
k <- 100
(1−(1/k))^(2*k)
distance <- function(pt1,centroid) {
result <- abs(centroid - pt1 )
return(result)
}
abs(-1)
distance(9,3)
length(points)
length(points)
length(points)
length(points)
points = c(6, 12, 18, 24, 30, 42, 48)
points = c(6, 12, 18, 24, 30, 42, 48)
length(points)
points = c(6, 12, 18, 24, 30, 42, 48)
#function that creates clusters
clustering <- function(points[], centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
data$cluster[i]= 2 #put it in cluster 2
}
}
return(points.cluster)
} #end clustering function
clustering <- function(points[], centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
data$cluster[i]= 2 #put it in cluster 2
}
}
return(points.cluster)
} #end clustering function
clustering <- function(points[], centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
data$cluster[i]= 2 #put it in cluster 2
}
}
return()
} #end clustering function
clustering <- function(points[], centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
data$cluster[i]= 2 #put it in cluster 2
}
}
} #end clustering function
clustering <- function(points[], centroid1, centroid2 ){
clustering <- function(points, centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
data$cluster[i]= 2 #put it in cluster 2
}
}
} #end clustering function
clustering(points, 18,45)
clustering <- function(points, centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
points.cluster[i]= 2 #put it in cluster 2
}
}
} #end clustering function
clustering(points, 18,45)
points.cluster
#function that creates clusters
clustering <- function(points, centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
points.cluster[i]= 2 #put it in cluster 2
}
}
return(points.cluster)
} #end clustering function
clustering(points, 18,45)
kmeans(points, 18)
kmeans(18, points)
kmeans(points, 2)
kmeans(points, c(18,45))
# making a user defined function to find distance b/w 1 dimensional point and centroid
distance <- function(pt1,centroid) {
result <- abs(centroid - pt1 )
return(result)
}
# vector of points
points = c(6, 12, 18, 24, 30, 42, 48)
#function that creates clusters
clustering <- function(points, centroid1, centroid2 ){
#initialize vector to store cluster number
points.cluster = c(0,0,0,0,0,0,0)
for(i in 1:length(points)){
distCen1 <- distance(points[i], centroid1)
distCen2 <- distance(points[i], centroid2)
if(distCen1 < distCen2){ # if the distance from centroid 1 < centroid 2
points.cluster[i]= 1 #put it in cluster 1
}else {
points.cluster[i]= 2 #put it in cluster 2
}
}
return(points.cluster)
} #end clustering function
clustering(points,18,45)
clustering(points,15,40)
SSE(points)
sse(points)
squarederror(points)
summary (points)
anova(points)
sse <- function(points, centroid){
sum <- 0 #initialize
for(i in 1:length(points)){
sum = sum + (distance(points[i], centroid))^2
}
}
sse(points, 18)
sse <- function(points, centroid){
sum <- 0 #initialize
for(i in 1:length(points)){
sum = sum + (distance(points[i], centroid))^2
}
return(sum)
}
sse(points, 18)
cluster1<-c(6,12, 18, 24, 30)
cluster2<-c(42, 48)
sse(cluster1, 18)
sse(cluster2,45)
sse.cluster1 <- sse(cluster1, 18)
sse.cluster1
sse.cluster1 <- sse(cluster1, 18) #find SSE for cluster 1
sse.cluster1 #view value
sse.cluster2 <- sse.cluster1 + sse(cluster2,45)# find SSE for cluster 2
sse.cluster2 #view value
#part a
cluster1<-c(6,12, 18, 24, 30)
cluster2<-c(42, 48)
sse.cluster1 <- sse(cluster1, 18) #find SSE for cluster 1
sse.cluster1 #view value
sse.cluster2 <- sse.cluster1 + sse(cluster2,45)# find SSE for cluster 2
sse.cluster2 #view value
cluster1<-c(6,12, 18, 24)
cluster2<-c(30,42,48)
sse.cluster1 <- sse(cluster1, 15) #find SSE for cluster 1
sse.cluster1 #view value
sse.cluster2 <- sse.cluster1 + sse(cluster2,40)# find SSE for cluster 2
sse.cluster2 #view value
r
r
cluster1<-c(6,12, 18, 24)
cluster2<-c(30,42,48)
sse(cluster1, 15) #find SSE for cluster 1
sse(cluster2,40)
total.error <- sse(cluster1,15) + sse(cluster2,40)# find SSE for cluster 2
total.error # view value
cluster1<-c(6,12, 18, 24, 30)
cluster1<-c(6,12, 18, 24, 30)
cluster2<-c(42, 48)
sse(cluster1, 18) #find SSE for cluster 1
sse(cluster2,45)# find SSE for cluster 2
total.error <- sse(cluster1, 18) + sse(cluster2,45)# find total error
total.error #view value
#part b
cluster1<-c(6,12, 18, 24)
cluster2<-c(30,42,48)
sse(cluster1, 15) #find SSE for cluster 1
sse(cluster2,40) # find SSE for cluster 2
total.error <- sse(cluster1,15) + sse(cluster2,40) #find total error
total.error # view value
#user function for total squared sum error of clusters
sse <- function(points, centroid){
sum <- 0 #initialize
for(i in 1:length(points)){
sum = sum + (distance(points[i], centroid))^2
}
return(sum)
}
#part a
cluster1<-c(6,12, 18, 24, 30)
cluster2<-c(42, 48)
sse(cluster1, 18) #find SSE for cluster 1
total.error <- sse(cluster1, 18) + sse(cluster2,45)# find total error
sse(cluster2,45)# find SSE for cluster 2
total.error #view value
#part b
cluster1<-c(6,12, 18, 24)
cluster2<-c(30,42,48)
sse(cluster1, 15) #find SSE for cluster 1
sse(cluster2,40) # find SSE for cluster 2
total.error <- sse(cluster1,15) + sse(cluster2,40) #find total error
total.error # view value
setwd("~/GitHub/pstat126-regression-project")
setwd("~/GitHub/pstat126-regression-project")
data = read.table(file.choose(), header = T)
data = read.table(file.choose(), header = T)
head(data)
dat = subset(data, select=-c(B,D,G,H,I))
dat
y = dat$A
x1 = dat$C  # displacement
x2 = dat$E  # weight
x3 = dat$F  # acceleration
fit1 = lm(y~x1+x2+x3)
summary(fit1)
confint(fit1)
pairs(dat, labels=c("MPG", "Displacement", "Weight", "Acceleration"))
plot(x1, residuals(fit1), main="Residuals vs Displacement", xlab="Cylinders",
summary(fit1)
summary(fit1)
View(y)
setwd("~/GitHub/pstat131-project")
data.train = read.table(file.choose())
view(data.train)
View(data.train)
data.train = read.table(file.choose())
View(data.train)
data.train = read.table(file.choose(), sep = ",")
View(data.train)
subject.train = read.table("UCI HAR Dataset/train/subject_train.txt")
View(subject.train)
x.train = read.table("UCI HAR Dataset/train/X_train.txt")
y.train = read.table("UCI HAR Dataset/train/y_train.txt")
y.test = read.table("UCI HAR Dataset/test/y_test.txt")
subject.test = read.table("UCI HAR Dataset/test/subject_test.txt")
x.test = read.table("UCI HAR Dataset/test/X_test.txt")
View(x.test)
